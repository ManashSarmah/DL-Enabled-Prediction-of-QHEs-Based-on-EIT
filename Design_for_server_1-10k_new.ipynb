{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb32ba35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 13:38:01.074725: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-26 13:38:02.619941: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-26 13:38:03.082809: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-02-26 13:38:03.082855: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-02-26 13:38:08.772258: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-26 13:38:08.772440: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-26 13:38:08.772459: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b91c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('updated_Data_till_T0_2-75_durga_oct17.csv')\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "data = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# Select the first 100 rows for training and testing\n",
    "data = data[:10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b271c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n1</th>\n",
       "      <th>l1</th>\n",
       "      <th>j1</th>\n",
       "      <th>n2</th>\n",
       "      <th>l2</th>\n",
       "      <th>j2</th>\n",
       "      <th>n3</th>\n",
       "      <th>l3</th>\n",
       "      <th>j3</th>\n",
       "      <th>LP</th>\n",
       "      <th>Te</th>\n",
       "      <th>Z</th>\n",
       "      <th>A</th>\n",
       "      <th>Rfq</th>\n",
       "      <th>T0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>55</td>\n",
       "      <td>133</td>\n",
       "      <td>259.3814</td>\n",
       "      <td>2.0496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.1038</td>\n",
       "      <td>55</td>\n",
       "      <td>133</td>\n",
       "      <td>259.3814</td>\n",
       "      <td>2.0493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>55</td>\n",
       "      <td>133</td>\n",
       "      <td>259.3814</td>\n",
       "      <td>2.0481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>55</td>\n",
       "      <td>133</td>\n",
       "      <td>259.3814</td>\n",
       "      <td>2.0451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.1558</td>\n",
       "      <td>55</td>\n",
       "      <td>133</td>\n",
       "      <td>259.3814</td>\n",
       "      <td>2.0394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676156</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9519</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>75306.6725</td>\n",
       "      <td>4.9398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676157</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9692</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>75306.6725</td>\n",
       "      <td>4.9395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676158</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>75306.6725</td>\n",
       "      <td>4.9392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676159</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0038</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>75306.6725</td>\n",
       "      <td>4.9390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676160</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0211</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>75306.6725</td>\n",
       "      <td>4.9387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4676161 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         n1  l1   j1  n2  l2   j2  n3  l3   j3      LP      Te   Z    A  \\\n",
       "0         6   2  1.5   7   2  1.5   8   3  2.5  0.0083  0.0865  55  133   \n",
       "1         6   2  1.5   7   2  1.5   8   3  2.5  0.0083  0.1038  55  133   \n",
       "2         6   2  1.5   7   2  1.5   8   3  2.5  0.0083  0.1211  55  133   \n",
       "3         6   2  1.5   7   2  1.5   8   3  2.5  0.0083  0.1385  55  133   \n",
       "4         6   2  1.5   7   2  1.5   8   3  2.5  0.0083  0.1558  55  133   \n",
       "...      ..  ..  ...  ..  ..  ...  ..  ..  ...     ...     ...  ..  ...   \n",
       "4676156  12   3  3.5  13   1  1.5  14   2  2.5  1.0000  0.9519  11   23   \n",
       "4676157  12   3  3.5  13   1  1.5  14   2  2.5  1.0000  0.9692  11   23   \n",
       "4676158  12   3  3.5  13   1  1.5  14   2  2.5  1.0000  0.9865  11   23   \n",
       "4676159  12   3  3.5  13   1  1.5  14   2  2.5  1.0000  1.0038  11   23   \n",
       "4676160  12   3  3.5  13   1  1.5  14   2  2.5  1.0000  1.0211  11   23   \n",
       "\n",
       "                Rfq      T0  \n",
       "0          259.3814  2.0496  \n",
       "1          259.3814  2.0493  \n",
       "2          259.3814  2.0481  \n",
       "3          259.3814  2.0451  \n",
       "4          259.3814  2.0394  \n",
       "...             ...     ...  \n",
       "4676156  75306.6725  4.9398  \n",
       "4676157  75306.6725  4.9395  \n",
       "4676158  75306.6725  4.9392  \n",
       "4676159  75306.6725  4.9390  \n",
       "4676160  75306.6725  4.9387  \n",
       "\n",
       "[4676161 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c6ad123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148430000.0, 18552832640000.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(df.Rfq.values)*10e7,np.max(df.Rfq.values)*10e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "975426c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.49"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(df.LP.values)*300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceb933eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(df.n2.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cd6f218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(df.n3.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc0731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input features and target variables\n",
    "input_features = ['n1', 'l1', 'j1', 'LP', 'Te', 'Z', 'A', 'Rfq', 'T0' ]\n",
    "target_variables = ['n2', 'l2', 'j2', 'n3', 'l3', 'j3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7df9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into input (X) and target (y) variables\n",
    "X = data[input_features]\n",
    "y = data[target_variables]\n",
    "\n",
    "# Normalize input features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3454e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ANN model as a function\n",
    "def create_model(learning_rate=0.001, num_units=64, activation='relu'):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(num_units, activation=activation, input_shape=(9,)),\n",
    "        layers.Dense(num_units, activation=activation),\n",
    "        layers.Dense(6)  # Output layer with 6 units for n2, l2, j2, n3, l3, j3\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f9175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform manual hyperparameter tuning\n",
    "def manual_hyperparameter_tuning(learning_rate_candidates, num_units_candidates, activation_candidates):\n",
    "    best_mae = float('inf')\n",
    "    best_hyperparameters = None\n",
    "    best_history = None\n",
    "\n",
    "    for lr in learning_rate_candidates:\n",
    "        for num_units in num_units_candidates:\n",
    "            for activation in activation_candidates:\n",
    "                model = create_model(learning_rate=lr, num_units=num_units, activation=activation)\n",
    "                history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, verbose=0)\n",
    "                y_pred = model.predict(X_test)\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "                if mae < best_mae:\n",
    "                    best_mae = mae\n",
    "                    best_hyperparameters = {'learning_rate': lr, 'num_units': num_units, 'activation': activation}\n",
    "                    best_history = history\n",
    "                    best_model = model  # Store the best model\n",
    "\n",
    "    return best_hyperparameters, best_history ,best_model ,best_mae\n",
    "\n",
    "# Define candidate hyperparameter values\n",
    "learning_rate_candidates = [0.001, 0.01, 0.1]\n",
    "num_units_candidates = [32, 64, 128]\n",
    "activation_candidates = ['relu', 'tanh']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d71e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform manual hyperparameter tuning\n",
    "best_hyperparameters, best_history, best_model,best_mae = manual_hyperparameter_tuning(learning_rate_candidates, num_units_candidates, activation_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03be03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506ce50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_loss =  best_history.history['loss']\n",
    "vl_loss =  best_history.history['val_loss']\n",
    "tr_mae = best_history.history['mean_absolute_error']\n",
    "vl_mae = best_history.history['val_mean_absolute_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b7d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(tr_loss),np.min(vl_loss),np.min(tr_mae),np.min(vl_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d43ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(tr_loss),np.min(vl_loss),np.min(tr_mae),np.min(vl_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6838562",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tt = np.array(best_history.history['val_mean_absolute_error'])/np.array(best_history.history['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3166da05",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee1fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0,100,100),tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c18b845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot learning curves\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(best_history.history['loss'])\n",
    "plt.plot(best_history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "# Plot training & validation MAE values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(best_history.history['mean_absolute_error'])\n",
    "plt.plot(best_history.history['val_mean_absolute_error'])\n",
    "plt.title('Mean Absolute Error (MAE)')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a004b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results for n2, l2, j2, n3, l3, j3 separately\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_test = pd.DataFrame(y_test, columns=target_variables)  # Define y_test if it's not defined\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, target in enumerate(target_variables):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.scatter(y_test[target], y_pred[:, i])\n",
    "    plt.xlabel(f'Actual {target}')\n",
    "    plt.ylabel(f'Predicted {target}')\n",
    "    plt.title(f'{target} Prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d99326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = y_test.values - y_pred\n",
    "\n",
    "# Plot individual error distributions for each target variable\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, target in enumerate(target_variables):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.hist(errors[:, i], bins=50, edgecolor='k')\n",
    "    plt.title(f'Error Distribution for {target}')\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbef49f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc030ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 13:52:25.256088: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-31 13:52:25.382044: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-31 13:52:25.385517: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-10-31 13:52:25.385530: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-10-31 13:52:25.979586: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-31 13:52:25.979636: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-31 13:52:25.979642: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/tmp/ipykernel_229548/827029903.py:10: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca1848d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('updated_Data_till_T0_2-75_durga_oct17.csv')\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "data = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# Select the first 100 rows for training and testing\n",
    "data = data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c585d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input features and target variables\n",
    "input_features = ['n1', 'l1', 'j1', 'LP', 'Te', 'Z', 'A', 'Rfq', 'T0' ]\n",
    "target_variables = ['n2', 'l2', 'j2', 'n3', 'l3', 'j3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "264910f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into input (X) and target (y) variables\n",
    "X = data[input_features]\n",
    "y = data[target_variables]\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a4fa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    for i in range(hp.Int('num_layers', 2, 20)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=512,\n",
    "                                            step=32),\n",
    "                               activation=hp.Choice('activation_' + str(i), values=['relu', 'tanh'])))\n",
    "    model.add(layers.Dense(6, activation=hp.Choice('output_activation', values=['linear', 'sigmoid', 'softmax'])))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='mean_absolute_error',\n",
    "        metrics=['mean_absolute_error'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a86906",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomSearch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_229381/989541542.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m tuner = RandomSearch(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mbuild_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmax_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mexecutions_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomSearch' is not defined"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mean_absolute_error',\n",
    "    max_trials=15,\n",
    "    executions_per_trial=5,\n",
    "    directory='ANN',\n",
    "    project_name='Trial',\n",
    "    loss='mean_absolute_error',\n",
    "    metrics=[\n",
    "        'mean_absolute_error',\n",
    "        keras.metrics.MeanSquaredError(name='mean_squared_error'),\n",
    "        keras.metrics.MeanAbsolutePercentageError(name='mean_absolute_percentage_error')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06b021af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 00m 12s]\n",
      "val_mean_absolute_error: 5.916666507720947\n",
      "\n",
      "Best val_mean_absolute_error So Far: 1.4345515966415405\n",
      "Total elapsed time: 00h 00m 47s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train,\n",
    "             epochs=5,\n",
    "             validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2f69ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, LeakyReLU, BatchNormalization, Dropout\n",
    "from keras.activations import relu, sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fae619b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_229548/201496250.py:16: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n",
      "2023-10-31 13:53:45.087874: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-10-31 13:53:45.087936: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-10-31 13:53:45.087977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (HPG-01): /proc/driver/nvidia/version does not exist\n",
      "2023-10-31 13:53:45.088490: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3fe1557e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3fe36ac160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-39.96800842285156,\n",
       " {'activation': 'sigmoid',\n",
       "  'batch_size': 128,\n",
       "  'epochs': 30,\n",
       "  'layers': [45, 30, 15]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_model(layers, activation):\n",
    "    model = Sequential()\n",
    "    for i, nodes in enumerate(layers):\n",
    "        if i==0:\n",
    "            model.add(Dense(nodes,input_dim=X_train.shape[1]))\n",
    "            model.add(Activation(activation))\n",
    "        else:\n",
    "            model.add(Dense(nodes))\n",
    "            model.add(Activation(activation))\n",
    "            \n",
    "    model.add(Dense(units = 6, kernel_initializer= 'he_uniform', activation = 'relu')) # Note: no activation beyond this point\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "    \n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "\n",
    "layers = [[20], [40, 20], [45, 30, 15]]\n",
    "activations = ['sigmoid', 'relu']\n",
    "param_grid = dict(layers=layers, activation=activations, batch_size = [128, 256], epochs=[30])\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid,cv=5)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "[grid_result.best_score_,grid_result.best_params_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17889cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-40.87155952453613"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5755416",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = grid_result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "071ae652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.49513268, 0.56026459, 0.80130181, 0.47986779, 0.5554255 ,\n",
       "        0.81198831, 0.49934931, 0.56431608, 0.66046724, 0.72831841,\n",
       "        0.71584764, 0.7692071 ]),\n",
       " 'std_fit_time': array([0.01333685, 0.01310889, 0.2485555 , 0.02112565, 0.01382652,\n",
       "        0.25226669, 0.02529144, 0.01149305, 0.01412798, 0.1989148 ,\n",
       "        0.02804995, 0.01733514]),\n",
       " 'mean_score_time': array([0.12653894, 0.11671572, 0.12872987, 0.12188139, 0.11687841,\n",
       "        0.13039994, 0.12313142, 0.12951717, 0.12444358, 0.15102763,\n",
       "        0.15369062, 0.14148126]),\n",
       " 'std_score_time': array([0.00386928, 0.00986311, 0.00425927, 0.00796818, 0.01271208,\n",
       "        0.01098706, 0.00690745, 0.0054737 , 0.00553197, 0.006523  ,\n",
       "        0.01195496, 0.00941802]),\n",
       " 'param_activation': masked_array(data=['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
       "                    'sigmoid', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_batch_size': masked_array(data=[128, 128, 128, 256, 256, 256, 128, 128, 128, 256, 256,\n",
       "                    256],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_epochs': masked_array(data=[30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_layers': masked_array(data=[list([20]), list([40, 20]), list([45, 30, 15]),\n",
       "                    list([20]), list([40, 20]), list([45, 30, 15]),\n",
       "                    list([20]), list([40, 20]), list([45, 30, 15]),\n",
       "                    list([20]), list([40, 20]), list([45, 30, 15])],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'activation': 'sigmoid',\n",
       "   'batch_size': 128,\n",
       "   'epochs': 30,\n",
       "   'layers': [20]},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 128,\n",
       "   'epochs': 30,\n",
       "   'layers': [40, 20]},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 128,\n",
       "   'epochs': 30,\n",
       "   'layers': [45, 30, 15]},\n",
       "  {'activation': 'sigmoid', 'batch_size': 256, 'epochs': 30, 'layers': [20]},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 256,\n",
       "   'epochs': 30,\n",
       "   'layers': [40, 20]},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 256,\n",
       "   'epochs': 30,\n",
       "   'layers': [45, 30, 15]},\n",
       "  {'activation': 'relu', 'batch_size': 128, 'epochs': 30, 'layers': [20]},\n",
       "  {'activation': 'relu', 'batch_size': 128, 'epochs': 30, 'layers': [40, 20]},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 128,\n",
       "   'epochs': 30,\n",
       "   'layers': [45, 30, 15]},\n",
       "  {'activation': 'relu', 'batch_size': 256, 'epochs': 30, 'layers': [20]},\n",
       "  {'activation': 'relu', 'batch_size': 256, 'epochs': 30, 'layers': [40, 20]},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 256,\n",
       "   'epochs': 30,\n",
       "   'layers': [45, 30, 15]}],\n",
       " 'split0_test_score': array([-37.93851471, -36.78731537, -38.09564209, -37.75606155,\n",
       "        -37.98700714, -37.97563553, -39.84408951, -37.88766479,\n",
       "        -37.74832535, -38.76484299, -37.08608246, -38.56888962]),\n",
       " 'split1_test_score': array([-52.62033844, -52.69737625, -53.23632431, -54.94136429,\n",
       "        -54.22137451, -54.03478241, -53.02420044, -53.30991364,\n",
       "        -53.22057343, -53.35130692, -53.73511124, -52.74529648]),\n",
       " 'split2_test_score': array([-47.34435272, -47.66950989, -48.86730194, -48.55789185,\n",
       "        -47.16313934, -47.87965012, -48.25366974, -47.72433472,\n",
       "        -47.83879852, -48.96769714, -48.60580826, -47.16312408]),\n",
       " 'split3_test_score': array([-30.15893745, -28.90531349, -29.11553764, -30.14622307,\n",
       "        -29.45678902, -28.47850227, -30.32106018, -29.83882713,\n",
       "        -29.35489845, -29.82853127, -29.37010193, -29.75090218]),\n",
       " 'split4_test_score': array([-49.4203949 , -47.13551712, -45.78819275, -46.77183533,\n",
       "        -47.17089844, -47.76289368, -48.07022095, -46.93986893,\n",
       "        -47.03458786, -47.96390152, -47.73003769, -48.26171875]),\n",
       " 'mean_test_score': array([-43.49650764, -42.63900642, -43.02059975, -43.63467522,\n",
       "        -43.19984169, -43.2262928 , -43.90264816, -43.14012184,\n",
       "        -43.03943672, -43.77525597, -43.30542831, -43.29798622]),\n",
       " 'std_test_score': array([8.26951878, 8.59711564, 8.53007017, 8.69962635, 8.59065011,\n",
       "        8.9902687 , 8.00542564, 8.28722507, 8.46065125, 8.43590323,\n",
       "        8.82409277, 8.18190006]),\n",
       " 'rank_test_score': array([ 9,  1,  2, 10,  5,  6, 12,  4,  3, 11,  8,  7], dtype=int32)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b485da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
